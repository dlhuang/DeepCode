{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Representation learning with Doc2Vec\n",
    "\n",
    "Practical course material for the ASDM Class 09 (Text Mining) by Florian Leitner.\n",
    "\n",
    "Â© 2017 Florian Leitner. All rights reserved.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In addition to word embeddings we just saw, it is possible to aggregate the word embeddings and combine them with a document-specific inference step to produce [Le and Mikolov (2014)](https://cs.stanford.edu/~quocle/paragraph_vector.pdf)'s approach for producing document embeddings, called *paragraph vectors*, aka. \"Doc2Vec\" (in analogy to \"Word2Vec\").\n",
    "\n",
    "The only requirement for this notebook is `gensim` and NTLK for the [Reuters-21578 corpus](https://archive.ics.uci.edu/ml/datasets/Reuters-21578+Text+Categorization+Collection).\n",
    "And we will be following a heavily modified version of `gensim`'s [Doc2Vec tutorial](https://nbviewer.jupyter.org/github/RaRe-Technologies/gensim/blob/develop/docs/notebooks/doc2vec-lee.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import os\n",
    "import nltk\n",
    "\n",
    "# show text as HTML\n",
    "from IPython.display import HTML\n",
    "%pylab inline --no-import-all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus preparation: Reuters-21578\n",
    "\n",
    "We will be using the same corpus we had in use yesterday for clustering, this time including the test data, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import reuters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above step didn't work, first download the Reuters corpus from the GUI that pops up here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a sample document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "ASIAN EXPORTERS FEAR DAMAGE FROM U.S.-JAPAN RIFT\n",
       "  Mounting trade friction between the\n",
       "  U.S. And Japan has raised fears among many of Asia's exporting\n",
       "  nations that the row could inflict far-reachin..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(reuters.raw(reuters.fileids()[0])[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The around 12,000 Reuters news articles in this corpus (the \"ApteMod\" corpus version) are assigned to the following categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all 90 categories:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "acq, alum, barley, bop, carcass, castor-oil, cocoa, coconut, coconut-oil, coffee, copper, copra-cake, corn, cotton, cotton-oil, cpi, cpu, crude, dfl, dlr, dmk, earn, fuel, gas, gnp, gold, grain, groundnut, groundnut-oil, heat, hog, housing, income, instal-debt, interest, ipi, iron-steel, jet, jobs, l-cattle, lead, lei, lin-oil, livestock, lumber, meal-feed, money-fx, money-supply, naphtha, nat-gas, nickel, nkr, nzdlr, oat, oilseed, orange, palladium, palm-oil, palmkernel, pet-chem, platinum, potato, propane, rand, rape-oil, rapeseed, reserves, retail, rice, rubber, rye, ship, silver, sorghum, soy-meal, soy-oil, soybean, strategic-metal, sugar, sun-meal, sun-oil, sunseed, tea, tin, trade, veg-oil, wheat, wpi, yen, zinc"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"all\", len(reuters.categories()), \"categories:\")\n",
    "HTML(\", \".join(reuters.categories()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa4AAAEWCAYAAAA+bHOCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njNEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11432a3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pairs = sorted([\n",
    "    (len(reuters.fileids(cat)), cat)\n",
    "    for cat in reuters.categories()\n",
    "])\n",
    "\n",
    "counts = [cnt for cnt, cat in pairs[-15:]]\n",
    "cats = [cat for cnt, cat in pairs[-15:]]\n",
    "plt.barh(range(len(cats)), counts)\n",
    "plt.yticks(range(len(cats)), cats)\n",
    "plt.xlabel('Counts')\n",
    "plt.title('Category counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the mean number of categories per document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean n. categories/document = 1.235\n"
     ]
    }
   ],
   "source": [
    "n_cat_sum = sum(len(reuters.categories(doc_id))\n",
    "                for doc_id in reuters.fileids())\n",
    "n_docs = len(reuters.fileids())\n",
    "print(\"mean n. categories/document = {:.3f}\".format(\n",
    "    n_cat_sum / n_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we go through the usual preprocessing setup we've seen these days already: tokenization, removing accents, removing stopwords and tokens with two or less characters, lemmatization of tokens, and forming bigram collocations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n. train docs: 7769\n",
      "n. test docs: 3019\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stopwords_en = (frozenset(stopwords.words('english'))\n",
    "                | frozenset([\"also\"]))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatize = lambda t: lemmatizer.lemmatize(t, pos='v')\n",
    "\n",
    "def read_and_tokenize(doc_id):\n",
    "    doc = reuters.raw(doc_id)\n",
    "    # strip accents and tokens with less than 3 characters\n",
    "    # NB: implicitly removes tokens *longer* than 15 characters\n",
    "    return simple_preprocess(doc, deacc=True, min_len=3)\n",
    "\n",
    "train_corpus = []\n",
    "test_corpus = []\n",
    "\n",
    "for doc_id in reuters.fileids():\n",
    "    doc = TaggedDocument(\n",
    "        simple_preprocess(reuters.raw(doc_id),\n",
    "                          deacc=True, min_len=3),\n",
    "        [doc_id])\n",
    "\n",
    "    if doc_id.startswith(\"train\"):\n",
    "        train_corpus.append(doc)\n",
    "    else:\n",
    "        test_corpus.append(doc)\n",
    "\n",
    "words = [d.words for d in train_corpus]\n",
    "collocations = Phraser(Phrases(words))\n",
    "\n",
    "def preprocess(doc):\n",
    "    \"\"\"\n",
    "    Stopword filtering,\n",
    "    collocation detection (joining),\n",
    "    and token lemmatization.\n",
    "    \"\"\"\n",
    "    \n",
    "    doc_filtered = filter(lambda w: w not in stopwords_en,\n",
    "                          doc.words)\n",
    "    doc_colloc = collocations[doc_filtered]\n",
    "    doc_lemmas = [lemmatize(token) for token in doc_colloc]\n",
    "    return TaggedDocument(doc_lemmas, doc.tags)\n",
    "\n",
    "train_corpus = [preprocess(d) for d in train_corpus]\n",
    "test_corpus = [preprocess(d) for d in test_corpus]\n",
    "\n",
    "print(\"n. train docs:\", len(train_corpus))\n",
    "print(\"n. test docs:\", len(test_corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training/1 tags : ['training/1']\n",
      "training/1 words:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "bahia cocoa review shower continue throughout week bahia cocoa zone alleviate drought since early january improve prospect come temporao although normal humidity level restore comissaria smith say weekly review dry period mean temporao late year arrivals week_ended february bag kilos make cumulative total season mln stage last_year seem cocoa deliver..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"training/1 tags :\", train_corpus[0].tags)\n",
    "print(\"training/1 words:\")\n",
    "HTML(\" \".join(train_corpus[0].words[:50]) + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the number of `tags` must be constant across all documents for Doc2Vec to work.\n",
    "And recall from the theory that `tags` is *not* a label, rather, its just an arbitrary, but unique (paragraph) ID for each document used during training (see Figures 2 and 3 in the Le & Mikolov paper).\n",
    "\n",
    "## Model training\n",
    "\n",
    "Gensim provides Le's paragraph vectors via its [Doc2Vec API](https://radimrehurek.com/gensim/models/doc2vec.html#gensim.models.doc2vec.Doc2Vec), which is based on the earlier Word2Vec API; It can be used to train the word embeddings at the same time (as the document embeddings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dbow+w,d45,n20,w5,mc2,s0.001,t4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(False, 1, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "model = Doc2Vec(\n",
    "    workers=4, # CPU cores, \"t\" (threads)\n",
    "    iter=10, # epochs; \n",
    "    # typically, use more than Word2Vec (5-30)\n",
    "    # -> increase iter until the consistency evaluation \"works\"\n",
    "    alpha=0.025, # learning rate \n",
    "    # might optimize this (0.5-0.001)\n",
    "    # -> related with iter/epochs changes; fine-tuning\n",
    "    size=len(reuters.categories()) // 2, # n. dim. \n",
    "    # -> optimize this (30-3000)\n",
    "    hs=0, negative=20, # use \"hs\" (1) or \"s\" (>0, range: 2-30)\n",
    "    # hs = hierarch. softmax\n",
    "    # s = neg. subsampling (rate)\n",
    "    window=5, # typically 5, might be optimized (2-30)\n",
    "    min_count=2, # min. freq. to add token to model\n",
    "    # filter junk and \"hard-to-learn\" words (1-10ish)\n",
    "    # -> a \"light\" regularization parameter\n",
    "    dm=0, dbow_words=1 # train with DM or DBOW (and W2V) model\n",
    ")\n",
    "# add the training documents\n",
    "model.build_vocab(train_corpus)\n",
    "print(model)\n",
    "# Doc2Vec(model,dimensions,....,threads)\n",
    "model.dm, model.dbow, model.sg\n",
    "# True 0 0 -> DM model\n",
    "# False 1 1 -> DBOW model (and words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the count for the word \"executive\" in the corpus is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vocab['executive'].count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traing should happen pretty fast - less than one minute on my quad-core machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 47s, sys: 394 ms, total: 1min 47s\n",
      "Wall time: 27.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4851324"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.train(\n",
    "    train_corpus,\n",
    "    total_examples=model.corpus_count,\n",
    "    epochs=model.iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document inference\n",
    "\n",
    "With this model in place, you can now build new document embedding vectors for an unseen document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.45949781,  0.05013795, -0.50757664, -0.18050912,  0.02658268,\n",
       "        0.27198178, -0.41617486, -0.29049665,  0.28125477, -0.50475585,\n",
       "       -0.09590899,  0.18044834,  0.00961993,  0.00209527,  0.50641751,\n",
       "       -0.19694327,  0.69898385, -0.29305515, -0.3271215 ,  0.10161357,\n",
       "        0.31647757,  0.53769004,  0.27872261, -0.43017522, -0.21492016,\n",
       "       -0.21783571,  0.40026492,  0.0870956 ,  0.15500104,  0.25074407,\n",
       "        0.35743505,  0.44467661, -0.24711996, -0.25583658, -0.26881629,\n",
       "       -0.24515086,  0.28306478,  0.46773168,  0.36428374,  0.23417291,\n",
       "       -0.09876581, -0.50789618, -0.25526094, -0.03906316,  0.09192097], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.infer_vector([\n",
    "    'a', 'trivial', 'sample', 'document',\n",
    "    'to', 'infer', 'an', 'embedding'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that each inference run produces slightly different results due to random sampling of the paragraph words (see the Le & Miklolov paper). Verify this by re-running the above cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model consistency check\n",
    "\n",
    "A simple way to assess the embeddings and the inference makes any sense at all is to self-test the model: That is, by infereing document vectors for each training set document, and verifying that the most similar document is the same as the input document using [`DocvecsArray.most_similar`](https://radimrehurek.com/gensim/models/doc2vec.html#gensim.models.doc2vec.DocvecsArray.most_similar).\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('training/14709', 0.9256892204284668),\n",
       " ('training/5362', 0.9256457686424255),\n",
       " ('training/12371', 0.9230365753173828),\n",
       " ('training/13158', 0.9217793345451355),\n",
       " ('training/14682', 0.9215726852416992),\n",
       " ('training/13272', 0.9206629991531372),\n",
       " ('training/14686', 0.9196255803108215),\n",
       " ('training/1143', 0.9189420938491821),\n",
       " ('training/1758', 0.9172046780586243),\n",
       " ('training/14701', 0.9167390465736389)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.docvecs.most_similar([\n",
    "    model.infer_vector([\n",
    "        'a', 'trivial', 'sample', 'document',\n",
    "        'to', 'infer', 'an', 'embedding'\n",
    "    ])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets run this over all documents and see where we stand; Because we must re-run the inference for each document, and then need to compare the simlilarity of the inferred vector against all known vectors, this might take a bit. To make this faster, we'll just check 10% of our documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank 1 document matched observed 709 times (91.4%)\n",
      "rank 2 document matched observed 30 times (3.9%)\n",
      "rank 3 document matched observed 6 times (0.8%)\n",
      "rank 4 document matched observed 4 times (0.5%)\n",
      "rank 5 document matched observed 4 times (0.5%)\n",
      "\n",
      "remaining ranks observed 23 times (3.0%)\n",
      "mean similiarity score = 0.957\n"
     ]
    }
   ],
   "source": [
    "from random import sample\n",
    "\n",
    "n_docs = len(train_corpus)\n",
    "n_trials = n_docs // 10\n",
    "ranks = [0] * n_docs\n",
    "similarty_sum = 0.\n",
    "# alias (save screen width)\n",
    "most_similar = model.docvecs.most_similar\n",
    "\n",
    "for doc in sample(train_corpus, n_trials):\n",
    "    inferred_vector = model.infer_vector(doc.words)\n",
    "    sims = most_similar([inferred_vector], topn=n_docs)\n",
    "    doc_ids = [doc_id for doc_id, sim in sims]\n",
    "    rank = doc_ids.index(doc.tags[0])\n",
    "    ranks[rank] += 1\n",
    "    similarty_sum += sims[rank][1]\n",
    "    \n",
    "for rank, count in enumerate(ranks[:5], 1):\n",
    "    if count > 0:\n",
    "        print(\"rank\", rank, \"document matched observed\", count,\n",
    "              \"times ({:.1f}%)\".format(100 * count / n_trials))\n",
    "\n",
    "print(\"\\nremaining ranks observed {:d} times ({:.1f}%)\".format(\n",
    "    sum(ranks[5:]),\n",
    "    100 * sum(ranks[5:]) / n_trials))\n",
    "print(\"mean similiarity score = {:.3f}\".format(\n",
    "    similarty_sum / n_trials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2MGO3gAKvgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1146b2748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(range(25)), ranks[:25])\n",
    "plt.title('Rank distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that your results will differ on each run of the above cell due to the random sampling and also because the model isn't very good due to the tiny corpus size. But you should observe a large mean (Cosine vector) similarity, like 0.8, and ideally above 0.9, and there should be a significant \"mass\" of documents that are matched with rank 1 (80% or more).\n",
    "\n",
    "## Model evaluation\n",
    "\n",
    "Next, lets use the following tactic to evaluate our model: How many of the categories of the query (i.e., test) document match with the best-matching indexed (i.e., train) document? You could use this, for example, to evaluate adding documents to category-specific clusters, or a nearest neighbor-like apporach for predicting document categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 2836/3744 = 75.75%\n",
      "Recall   : 2836/3706 = 76.52%\n",
      "\n",
      "mean   similiarity score = 0.874\n",
      "median similiarity score = 0.877\n"
     ]
    }
   ],
   "source": [
    "similarties = []\n",
    "n_docs = len(test_corpus)\n",
    "hits = 0\n",
    "pred_cats = 0\n",
    "ann_cats = 0\n",
    "# alias (save screen width)\n",
    "most_similar = model.docvecs.most_similar\n",
    "\n",
    "for doc in test_corpus:\n",
    "    test_id = doc.tags[0]\n",
    "    test_cats = set(reuters.categories(test_id))\n",
    "    \n",
    "    inferred_vector = model.infer_vector(doc.words)\n",
    "    \n",
    "    match_id, sim = most_similar([inferred_vector], topn=1)[0]\n",
    "    match_cats = set(reuters.categories(match_id))\n",
    "    \n",
    "    similarties.append(sim)\n",
    "    hits += len(test_cats & match_cats)\n",
    "    pred_cats += len(test_cats)\n",
    "    ann_cats += len(match_cats)\n",
    "\n",
    "similarties = sorted(similarties)\n",
    "\n",
    "print(\"Precision: {:d}/{:d} = {:.2f}%\".format(\n",
    "    hits, pred_cats,\n",
    "    100 * hits / pred_cats))\n",
    "print(\"Recall   : {:d}/{:d} = {:.2f}%\\n\".format(\n",
    "    hits, ann_cats,\n",
    "    100 * hits / ann_cats))\n",
    "print(\"mean   similiarity score = {:.3f}\".format(\n",
    "    sum(similarties) / n_docs))\n",
    "print(\"median similiarity score = {:.3f}\".format(\n",
    "    similarties[n_docs//2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step back a moment and let this sink in: We've achieved a category prediction performance that maybe does not (yet) beat the supervised methods we looked into on day one. Without ever conditioning the model on the categories, we've achieved a result that is far beyond random predictions (Reuters-21578 has 90 categories). That is, the paragraph vector model figured out the documents' semantics all on its own, and we never told it anything about the categories, yet it clearly is able to make sensible matches, retrieving documents from the same categories.\n",
    "\n",
    "Our above evaluation setup resembles that of a traditional nearest neighbor classifier. For reference, the highest score a (heavily optimized) kNN classifier ever achieved on this dataset is a [86% micro-averaged $F_1$-score](https://www.aaai.org/Papers/ICML/2003/ICML03-063.pdf) (see Figure 2). But the best kNN classifier used 2000 features, while our model only has 45 dimensions (i.e., features), those feature vectors are generated fully **unsupervised**, and they can be used to train (supervised) classifiers (see the Le & Mikolov paper, where they evaluated paragraph vectors feeding a logistic regression classifier on various datasets and tasks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basline precision (predict earn always): 36.0%\n",
      "Basline recall    (predict earn always): 29.0%\n"
     ]
    }
   ],
   "source": [
    "# document IDs labeled \"earn\" that start with \"test/\"\n",
    "hits = sum(1 for f in reuters.fileids(\"earn\")\n",
    "           if f.startswith(\"test/\"))\n",
    "\n",
    "test_docs = [f for f in reuters.fileids()\n",
    "             if f.startswith(\"test/\")]\n",
    "\n",
    "# n. labels on of test documents\n",
    "n_cats = sum(len(reuters.categories(f)) for f in test_docs)\n",
    "\n",
    "print(\"Basline precision (predict earn always): {:.1f}%\".format(\n",
    "    100 * hits / len(test_docs)))\n",
    "\n",
    "print(\"Basline recall    (predict earn always): {:.1f}%\".format(\n",
    "    100 * hits / n_cats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the Reuters categories are highly imbalanced, and just predicting the majority label (`earn`) gives you a 32% micro-averaged $F_1$ on this set (i.e., the best \"test dummy\" baseline, maybe).\n",
    "\n",
    "## Conclusions\n",
    "\n",
    "Finally we have arrived at the \"core\" of statistical text mining: we can now easily convert a document into small-ish (< 1000) arrays of numbers. And we've emulated supervised models using only \"represenation learning\" techniques that are fully unsupervised. It should go without saying that even more impressive results can be achieved by combining the two approaches: first, use representation learning to create document vectors and then use supervised learning to predict the correct label(s), using the document vectors as input (instead of the noisy, sparse bag-of-word vectors)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
