{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function\n",
    "import numpy\n",
    "\n",
    "import spacy\n",
    "from spacy.language import Language\n",
    "\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "numberbatch_word2vector = '/Users/newscred/Data/numberbatch-en.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy WordVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class colspan 0.0\n"
     ]
    }
   ],
   "source": [
    "def main(lang=None):\n",
    "    if lang is None:\n",
    "        nlp = Language()\n",
    "    else:\n",
    "        nlp = spacy.blank(lang)\n",
    "        \n",
    "    with open(numberbatch_word2vector, 'rb') as file_:\n",
    "        header = file_.readline()\n",
    "        nr_row, nr_dim = header.split()\n",
    "        nlp.vocab.reset_vectors(width=int(nr_dim))\n",
    "        for line in file_:\n",
    "            line = line.decode('utf8')\n",
    "            pieces = line.rsplit(' ', int(nr_dim))\n",
    "            word = pieces[0]\n",
    "            vector = numpy.asarray([float(v) for v in pieces[1:]], dtype='f')\n",
    "            nlp.vocab.set_vector(word, vector)  # add the vectors to the vocab\n",
    "            \n",
    "    # test the vectors and similarity\n",
    "    text = 'class colspan'\n",
    "    doc = nlp(text)\n",
    "    print(text, doc[0].similarity(doc[1]))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim WordVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tokens: 417194\n",
      "Dimension of a word vector: 300\n"
     ]
    }
   ],
   "source": [
    "en_model = KeyedVectors.load_word2vec_format(numberbatch_word2vector)\n",
    "\n",
    "# Getting the tokens \n",
    "words = []\n",
    "for word in en_model.vocab:\n",
    "    words.append(word)\n",
    "\n",
    "# Printing out number of tokens available\n",
    "print(\"Number of Tokens: {}\".format(len(words)))\n",
    "\n",
    "# Printing out the dimension of a word vector \n",
    "print(\"Dimension of a word vector: {}\".format(\n",
    "    len(en_model[words[0]])\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/newscred/.pyenv/versions/3.6.3/lib/python3.6/site-packages/gensim/models/keyedvectors.py:1046: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.syn0norm = (self.syn0 / sqrt((self.syn0 ** 2).sum(-1))[..., newaxis]).astype(REAL)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: unanalytical, Similarity: 0.95\n",
      "Word: analytic, Similarity: 0.85\n",
      "Word: analytic_signal, Similarity: 0.80\n",
      "Word: analytic_set, Similarity: 0.80\n",
      "Word: bioanalytics, Similarity: 0.78\n",
      "Word: gravimetric_analysis, Similarity: 0.76\n",
      "Word: analytic_continuation, Similarity: 0.75\n",
      "Word: x_ray_spectroscopy, Similarity: 0.74\n",
      "Word: wet_chemistry, Similarity: 0.74\n",
      "Word: trend_analysis, Similarity: 0.73\n",
      "Word: analytics, Similarity: 0.73\n",
      "Word: chronoamperometry, Similarity: 0.73\n",
      "Word: analysis, Similarity: 0.72\n",
      "Word: statistical_analysis, Similarity: 0.71\n",
      "Word: calibrant, Similarity: 0.70\n",
      "Word: chemical_analysis, Similarity: 0.70\n",
      "Word: cost_analysis, Similarity: 0.70\n",
      "Word: volumetric_analysis, Similarity: 0.70\n",
      "Word: chronoamperometric, Similarity: 0.70\n",
      "Word: quantitative_analysis, Similarity: 0.69\n",
      "Word: macroanalysis, Similarity: 0.69\n",
      "Word: manganometry, Similarity: 0.69\n",
      "Word: integration_by_parts, Similarity: 0.68\n",
      "Word: fourier_analysis, Similarity: 0.68\n",
      "Word: analytical_chemistry, Similarity: 0.68\n"
     ]
    }
   ],
   "source": [
    "# Pick a word \n",
    "find_similar_to = 'analytical'\n",
    "\n",
    "# Finding out similar words [default= top 10]\n",
    "for similar_word in en_model.similar_by_word(find_similar_to, topn=25):\n",
    "    print(\"Word: {0}, Similarity: {1:.2f}\".format(\n",
    "        similar_word[0], similar_word[1]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
