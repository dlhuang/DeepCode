{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence segmentation\n",
    "\n",
    "Practical course material for the ASDM Class 09 (Text Mining) by Florian Leitner.\n",
    "\n",
    "© 2017 Florian Leitner. All rights reserved.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import segtok\n",
    "import nltk\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(If either the above imports failed, please install the missing Python modules; \"`pip3 install MODULE_NAME`\".)\n",
    "\n",
    "To use `spacy`, you will also have to have downloaded at least the English models, too; To do that, run the following command in your terminal:\n",
    "\n",
    "```shell\n",
    "python3 -m spacy download en\n",
    "```\n",
    "\n",
    "As for NLTK's data, we already saw how to download that yesterday.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "NLTK's current default sentence splitter (available as `nltk.sent_tokenize`) is an implmentation of the **unsupervised** [Punkt Sentence Tokenizer](http://www.nltk.org/api/nltk.tokenize.html#module-nltk.tokenize.punkt) with the properties discussed in class (day 2, first three slides).\n",
    "\n",
    "The other two solutions we'll look at is a **supervised** model that learns to split sentences from pre-splitted text (SpaCy), and a **rule-based** model that your instructor keeps maintaining (`segtok`).\n",
    "\n",
    "First, pre-load everything necessary for sentence splitting by each module/approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from segtok.segmenter import split_multi, split_single\n",
    "from nltk import sent_tokenize\n",
    "# import spacy\n",
    "\n",
    "spacy_en = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, define a list of sentences that are known to be hard to split and see how the segmenters perform on those cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n. sentences = 50\n"
     ]
    }
   ],
   "source": [
    "tricky_stuff = \"\"\"One sentence per line.\n",
    "And another sentence on the same line.\n",
    "(How about a sentence in parenthesis?)\n",
    "Or a sentence with \"a quote!\"\n",
    "'How about those pesky single quotes?'\n",
    "[And not to forget about square brackets.]\n",
    "And, brackets before the terminal [2].\n",
    "You know Mr. Abbreviation I told you so.\n",
    "What about the med. staff here?\n",
    "But the undef. abbreviation not.\n",
    "And this f.e. is tricky stuff.\n",
    "I.e. a little easier here.\n",
    "However, e.g., should be really easy.\n",
    "Three is one btw., is clear.\n",
    "Their presence was detected by transformation into S. lividans.\n",
    "Three subjects diagnosed as having something.\n",
    "What the heck??!?!\n",
    "(A) First things here.\n",
    "(1) No, they go here.\n",
    "[z] Last, but not least.\n",
    "(vii) And the Romans, too.\n",
    "Let's meet at 14.10 in N.Y..\n",
    "This happened in the U.S. last week.\n",
    "Brexit: The E.U. and the U.K. are separating.\n",
    "Refugees are welcome in the E.U..\n",
    "The U.S. Air Force was called in.\n",
    "What about the E.U. High Court?\n",
    "And then there is the U.K. House of Commons.\n",
    "Now only this splits: the EU.\n",
    "A sentence ending in U.S.\n",
    "Another that won't split.\n",
    "12 monkeys ran into here.\n",
    "In the Big City.\n",
    "How he got an A.\n",
    "Mathematics . dot times.\n",
    "An abbreviation at the fin..\n",
    "This is a sentence terminal ellipsis...\n",
    "This is another sentence terminal ellipsis....\n",
    "An easy to handle G. species mention.\n",
    "Am 13. Jän. 2006 war es regnerisch.\n",
    "The basis for Lester B. Pearson's initials was developed later.\n",
    "This model was introduced by Dr. Edgar F. Codd after criticisms.\n",
    "This quote \"He said it.\" is actually inside.\n",
    "A. The first assumption.\n",
    "B. The second bullet.\n",
    "C. The last case.\n",
    "1. This is one.\n",
    "2. And that is two.\n",
    "3. Finally, three, too.\n",
    "Always last, a simple final sentence example.\"\"\"\n",
    "\n",
    "input_text = tricky_stuff.replace('\\n', ' ')\n",
    "expected_sentences = tricky_stuff.split('\\n')\n",
    "print(\"n. sentences =\", len(expected_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One sentence per line.\n",
      "And another sentence on the same line.\n",
      "(How about a sentence in parenthesis?)\n",
      "Or a sentence with \"a quote!\"\n",
      "'How about those pesky single quotes?'\n",
      "[And not to forget about square brackets.]\n",
      "And, brackets before the terminal [2].\n",
      "You know Mr.\n",
      "Abbreviation I told you so.\n",
      "What about the med.\n",
      "staff here?\n",
      "But the undef.\n",
      "abbreviation not.\n",
      "And this f.e.\n",
      "is tricky stuff.\n",
      "I.e.\n",
      "a little easier here.\n",
      "However, e.g., should be really easy.\n",
      "Three is one btw., is clear.\n",
      "Their presence was detected by transformation into S. lividans.\n",
      "Three subjects diagnosed as having something.\n",
      "What the heck??!?!\n",
      "(A) First things here.\n",
      "(1) No, they go here.\n",
      "[z] Last, but not least.\n",
      "(vii) And the Romans, too.\n",
      "Let's meet at 14.10 in N.Y..\n",
      "This happened in the U.S. last week.\n",
      "Brexit: The E.U.\n",
      "and the U.K. are separating.\n",
      "Refugees are welcome in the E.U..\n",
      "The U.S. Air Force was called in.\n",
      "What about the E.U.\n",
      "High Court?\n",
      "And then there is the U.K. House of Commons.\n",
      "Now only this splits: the EU.\n",
      "A sentence ending in U.S. Another that won't split.\n",
      "12 monkeys ran into here.\n",
      "In the Big City.\n",
      "How he got an A.\n",
      "Mathematics .\n",
      "dot times.\n",
      "An abbreviation at the fin..\n",
      "This is a sentence terminal ellipsis...\n",
      "This is another sentence terminal ellipsis.... An easy to handle G. species mention.\n",
      "Am 13.\n",
      "Jän.\n",
      "2006 war es regnerisch.\n",
      "The basis for Lester B. Pearson's initials was developed later.\n",
      "This model was introduced by Dr. Edgar F. Codd after criticisms.\n",
      "This quote \"He said it.\"\n",
      "is actually inside.\n",
      "A.\n",
      "The first assumption.\n",
      "B.\n",
      "The second bullet.\n",
      "C. The last case.\n",
      "1.\n",
      "This is one.\n",
      "2.\n",
      "And that is two.\n",
      "3.\n",
      "Finally, three, too.\n",
      "Always last, a simple final sentence example.\n",
      "\n",
      "n. sentences = 64\n"
     ]
    }
   ],
   "source": [
    "from nltk import sent_tokenize\n",
    "\n",
    "for sentence in sent_tokenize(input_text):\n",
    "    print(sentence)\n",
    "    \n",
    "print(\"\\nn. sentences =\",\n",
    "      len(sent_tokenize(input_text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One sentence per line.\n",
      "And another sentence on the same line.\n",
      "(How about a sentence in parenthesis?)\n",
      "Or a sentence with \"a quote!\" 'How about those pesky single quotes?' [And not to forget about square brackets.]\n",
      "And, brackets before the terminal [2]. You know\n",
      "Mr. Abbreviation I told you so.\n",
      "What about the med.\n",
      "staff here?\n",
      "But the undef.\n",
      "abbreviation not.\n",
      "And this f.e. is tricky stuff.\n",
      "I.e. a little easier here.\n",
      "However, e.g., should be really easy.\n",
      "Three is one btw.\n",
      ", is clear.\n",
      "Their presence was detected by transformation into S. lividans.\n",
      "Three subjects diagnosed as having something.\n",
      "What the heck??!?!\n",
      "(A) First things here.\n",
      "(1) No, they go here.\n",
      "[z] Last, but not least.\n",
      "(vii) And the Romans, too.\n",
      "Let's meet at 14.10 in N.Y..\n",
      "This happened in the U.S. last week.\n",
      "Brexit: The E.U. and the U.K. are separating.\n",
      "Refugees are welcome in the E.U..\n",
      "The U.S. Air Force was called in.\n",
      "What about the E.U. High Court?\n",
      "And then there is the U.K. House of Commons.\n",
      "Now only this splits: the EU.\n",
      "A sentence ending in U.S.\n",
      "Another that won't split.\n",
      "12 monkeys ran into here.\n",
      "In the Big City.\n",
      "How he got an A. Mathematics .\n",
      "dot times.\n",
      "An abbreviation at the fin..\n",
      "This is a sentence terminal ellipsis...\n",
      "This is another sentence terminal ellipsis....\n",
      "An easy to handle G. species mention.\n",
      "Am 13.\n",
      "Jän.\n",
      "2006 war es regnerisch.\n",
      "The basis for Lester B. Pearson's initials was developed later.\n",
      "This model was introduced by Dr. Edgar F. Codd after criticisms.\n",
      "This quote \"\n",
      "He said it.\"\n",
      "is actually inside.\n",
      "A. The first assumption.\n",
      "B. The second bullet.\n",
      "C. The last case.\n",
      "1.\n",
      "This is one.\n",
      "2.\n",
      "And that is two.\n",
      "3.\n",
      "Finally, three, too.\n",
      "Always last, a simple final sentence example.\n",
      "\n",
      "n. sentences = 58\n"
     ]
    }
   ],
   "source": [
    "spacy_doc = spacy_en(input_text)\n",
    "\n",
    "for sentence in spacy_doc.sents:\n",
    "    print(sentence)\n",
    "\n",
    "print(\"\\nn. sentences =\",\n",
    "      len(list(spacy_doc.sents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With `segtok`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One sentence per line.\n",
      "And another sentence on the same line.\n",
      "(How about a sentence in parenthesis?)\n",
      "Or a sentence with \"a quote!\"\n",
      "'How about those pesky single quotes?'\n",
      "[And not to forget about square brackets.]\n",
      "And, brackets before the terminal [2].\n",
      "You know Mr. Abbreviation I told you so.\n",
      "What about the med. staff here?\n",
      "But the undef.\n",
      "abbreviation not.\n",
      "And this f.e. is tricky stuff.\n",
      "I.e. a little easier here.\n",
      "However, e.g., should be really easy.\n",
      "Three is one btw., is clear.\n",
      "Their presence was detected by transformation into S. lividans.\n",
      "Three subjects diagnosed as having something.\n",
      "What the heck??!?!\n",
      "(A) First things here.\n",
      "(1) No, they go here.\n",
      "[z] Last, but not least.\n",
      "(vii) And the Romans, too.\n",
      "Let's meet at 14.10 in N.Y..\n",
      "This happened in the U.S. last week.\n",
      "Brexit: The E.U. and the U.K. are separating.\n",
      "Refugees are welcome in the E.U..\n",
      "The U.S. Air Force was called in.\n",
      "What about the E.U. High Court?\n",
      "And then there is the U.K. House of Commons.\n",
      "Now only this splits: the EU.\n",
      "A sentence ending in U.S. Another that won't split.\n",
      "12 monkeys ran into here.\n",
      "In the Big City.\n",
      "How he got an A.\n",
      "Mathematics . dot times.\n",
      "An abbreviation at the fin..\n",
      "This is a sentence terminal ellipsis...\n",
      "This is another sentence terminal ellipsis....\n",
      "An easy to handle G. species mention.\n",
      "Am 13. Jän. 2006 war es regnerisch.\n",
      "The basis for Lester B. Pearson's initials was developed later.\n",
      "This model was introduced by Dr. Edgar F. Codd after criticisms.\n",
      "This quote \"He said it.\" is actually inside.\n",
      "A. The first assumption.\n",
      "B. The second bullet.\n",
      "C. The last case.\n",
      "1. This is one.\n",
      "2. And that is two.\n",
      "3. Finally, three, too.\n",
      "Always last, a simple final sentence example.\n",
      "\n",
      "n. sentences = 50\n"
     ]
    }
   ],
   "source": [
    "for sentence in split_multi(input_text):\n",
    "    print(sentence)\n",
    "\n",
    "print(\"\\nn. sentences =\",\n",
    "      len(list(split_multi(input_text))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostly, sentence segmenters tend to over-split (abbrevations, enumerations, European dates (with dots)), but the also under-split, e.g., inside quotes or sentencens ending with single letters (probably \"mistaken\" for initials). As most language processing systems tend to work on the sentence level (because it is easier to handle), this chronic oversplitting may harm the baseline performance of your system. However, as always: Before jumping at `segtok` for your sentence segmentation needs - test your assumptions on a sample corpus of the text you want to process!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
