{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extractive summarization with `gensim`\n",
    "\n",
    "Practical course material for the ASDM Class 09 (Text Mining) by Florian Leitner.\n",
    "\n",
    "Â© 2017 Florian Leitner. All rights reserved.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook explains how to use [gensim](http://radimrehurek.com/gensim/index.html), for document summarization, closely following [its own tutorial for extractive summarization](https://nbviewer.jupyter.org/github/RaRe-Technologies/gensim/blob/develop/docs/notebooks/summarization_tutorial.ipynb).\n",
    "\n",
    "## Setup\n",
    "\n",
    "Inline with the class' content for Day 5, the gensim summarizer is based on TextRank, a graph-based content extraction technique published ([in parallel](https://en.wikipedia.org/wiki/Automatic_summarization#TextRank_and_LexRank)) by [Mihalcea et al. (2004)](http://web.eecs.umich.edu/%7Emihalcea/papers/mihalcea.emnlp04.pdf) (and by [Erkan and Radev (2004)](http://www.jair.org/media/1523/live-1523-2354-jair.pdf) as LexRank, with some additional features), and also includes the BM25 ranking-based improvement described by [Barrios et al. (2015)](https://arxiv.org/abs/1602.03606). In turn, both LexRank and TextRank are based on PageRank (Google's world-famous link ranking algorithm), explaining their names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Thomas A. Anderson is a man living two lives. By day he is an\n",
    "average computer programmer and by night a hacker known as\n",
    "Neo. Neo has always questioned his reality, but the truth is\n",
    "far beyond his imagination. Neo finds himself targeted by the\n",
    "police when he is contacted by Morpheus, a legendary computer\n",
    "hacker branded a terrorist by the government. Morpheus awakens\n",
    "Neo to the real world, a ravaged wasteland where most of\n",
    "humanity have been captured by a race of machines that live\n",
    "off of the humans' body heat and electrochemical energy and\n",
    "who imprison their minds within an artificial reality known as\n",
    "the Matrix. As a rebel against the machines, Neo must return to\n",
    "the Matrix and confront the agents: super-powerful computer\n",
    "programs devoted to snuffing out Neo and the entire human\n",
    "rebellion.\n",
    "\"\"\".replace('\\n', ' ').strip() # NB: we removed newlines\n",
    "# (otherwise gensim assumes those are sentence breaks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim mindfully warns us that we're actually abusing its API; To make those warnings dissappear and better concentrate on the result, click on the link this cell generates in its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<script>\n",
       "  code_show_err=false; \n",
       "  function code_toggle_err(a) {\n",
       "   if (code_show_err){\n",
       "     $('div.output_stderr').hide();\n",
       "   } else {\n",
       "     $('div.output_stderr').show();\n",
       "   }\n",
       "   code_show_err = !code_show_err\n",
       "  } \n",
       "  $( document ).ready(code_toggle_err);\n",
       "</script>\n",
       "To toggle on/off output_stderr, click\n",
       "<a href=\"javascript:code_toggle_err()\">here</a>.\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('''\n",
    "<script>\n",
    "  code_show_err=false; \n",
    "  function code_toggle_err(a) {\n",
    "   if (code_show_err){\n",
    "     $('div.output_stderr').hide();\n",
    "   } else {\n",
    "     $('div.output_stderr').show();\n",
    "   }\n",
    "   code_show_err = !code_show_err\n",
    "  } \n",
    "  $( document ).ready(code_toggle_err);\n",
    "</script>\n",
    "To toggle on/off output_stderr, click\n",
    "<a href=\"javascript:code_toggle_err()\">here</a>.\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Morpheus awakens Neo to the real world, a ravaged wasteland where most of humanity have been captured by a race of machines that live off of the humans' body heat and electrochemical energy and who imprison their minds within an artificial reality known as the Matrix."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.summarization import summarize\n",
    "\n",
    "HTML(summarize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim quite practically lets you define an approximate percentage of the input text that you want to have as the summary, using 20% as default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "By day he is an average computer programmer and by night a hacker known as Neo. Neo has always questioned his reality, but the truth is far beyond his imagination.\n",
       "Morpheus awakens Neo to the real world, a ravaged wasteland where most of humanity have been captured by a race of machines that live off of the humans' body heat and electrochemical energy and who imprison their minds within an artificial reality known as the Matrix.\n",
       "As a rebel against the machines, Neo must return to the Matrix and confront the agents: super-powerful computer programs devoted to snuffing out Neo and the entire human rebellion."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(summarize(text, ratio=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword extraction from documents\n",
    "\n",
    "Although this is a bit getting ahead of ourselves, on day 4 we will see that the TextRank algorithm can also be used to extract **keywords**, and gensim provides that API functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "humanity\n",
       "human\n",
       "neo\n",
       "humans body\n",
       "super\n",
       "reality\n",
       "hacker"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.summarization import keywords\n",
    "\n",
    "HTML(keywords(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this result might be improved if you first detect collocations (as we will discuss on day 4).\n",
    "\n",
    "## Keyword extraction from corpora\n",
    "\n",
    "Finally, gensim also allows you to extract keywords from entire document collection (corpus).\n",
    "\n",
    "First, we generate a corpus just as we did for the first clustering (I) approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim, os\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "test_data_dir = (os.sep).join([\n",
    "    gensim.__path__[0], 'test', 'test_data'\n",
    "])\n",
    "lee_train_file = (\n",
    "    test_data_dir + os.sep + 'lee_background.cor'\n",
    ")\n",
    "\n",
    "def read_and_tokenize(file_path):\n",
    "    with open(file_path) as f:\n",
    "        for doc in f:\n",
    "            yield simple_preprocess(doc, min_len=3)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stopwords_en = (frozenset(stopwords.words('english'))\n",
    "                | frozenset([\"also\"]))\n",
    "\n",
    "def preprocess(doc):\n",
    "    \"\"\"\n",
    "    Stopword filtering,\n",
    "    collocation detection (joining),\n",
    "    and token lemmatization.\n",
    "    \"\"\"\n",
    "    \n",
    "    doc_filtered = filter(lambda w: w not in stopwords_en,\n",
    "                          doc)\n",
    "    doc_colloc = collocations[doc_filtered]\n",
    "    return [lemmatizer.lemmatize(token, pos='v')\n",
    "            for token in doc_colloc]\n",
    "\n",
    "raw_documents = list(read_and_tokenize(lee_train_file))\n",
    "collocations = Phraser(Phrases(raw_documents))\n",
    "\n",
    "texts = list(map(preprocess, raw_documents))\n",
    "dictionary = Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use gensim to summarize our BoW documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.2 s, sys: 171 ms, total: 8.37 s\n",
      "Wall time: 8.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from gensim.summarization import summarize_corpus\n",
    "\n",
    "selection = summarize_corpus(corpus, 1/30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selection) # 300 * 1/30 = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "crew hundreds detail southern long aedt nearby place do move still rain force part cause arrest across capital december decision town come towards group huge new_south today people leave militants near call carry state residents make defend night two sydney authorities suspect police five around less strong areas north push new highlands meanwhile eight wales firefighters far take"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def collect_words(summary_selection, top_n=10):\n",
    "    for doc_number, tokens in enumerate(summary_selection):\n",
    "        tokens = sorted(tokens, key=lambda t: t[1])\n",
    "        yield [dictionary[token_id]\n",
    "               for (token_id, count) in tokens[:top_n]]\n",
    "\n",
    "HTML(\" \".join(set(word \n",
    "                  for d in collect_words(selection)\n",
    "                  for word in d)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay! **Extractive** *document summarization* and *keyword extraction* have never been simpler!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
