{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embeddings: Word2Vec, GloVe, and FastText\n",
    "\n",
    "Practical course material for the ASDM Class 09 (Text Mining) by Florian Leitner.\n",
    "\n",
    "Â© 2017 Florian Leitner. All rights reserved.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This lab will look into the three most common algorithms to generate word embeddings.\n",
    "\n",
    "First, we need to make sure we have all tools on board; It might not be possible for you to install all three requirements, but you should at least be able to get Word2Vec to work, as it is based on `gensim`, which we've been using yesterday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fasttext # requires cython\n",
    "import gensim # for Word2Vec\n",
    "import glove # package name: glove_python; only easy to install on Linux\n",
    "\n",
    "from IPython.display import HTML # show text as HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installation notes for [**`fasttext`**](https://github.com/salestock/fastText.py): You will need to have [Cython](http://cython.org/) installed on your machine (e.g., with Homebrew: `brew install cython`). Attention: you will need to **`unset`** the `$CXX` and `$CC` environment variables (see below) used for `glove_python` to install `fasttext` (or first install `fasttext`).\n",
    "\n",
    "Installation notes for [**`glove_python`**](https://github.com/maciejkula/glove-python) on OSX: You will need to have [Homebrew](https://brew.sh/) installed, and will need a new C/C++ compiler, as Apple's `clang` does not support the required features:\n",
    "\n",
    "```sh\n",
    "brew ls gcc\n",
    "# ONLY if no gcc is installed:\n",
    "brew install gcc --without-multilib\n",
    "export CXX=/usr/local/Cellar/gcc/VERSION/bin/g++-7\n",
    "export CC=/usr/local/Cellar/gcc/7.1.0/bin/gcc-7\n",
    "$YOUR_PY_PKG_MANGER install glove_python\n",
    "```\n",
    "\n",
    "## Data preparation\n",
    "\n",
    "We will be using `text8`, a standard text file used for evaluating text compression algorithms that turns out to be sufficiently large (or, small...) and therefore very practical for a mini-evaluation of text embeddings. Do note though that \"real\" text copopra to learn embeddings should be in the GB size range.\n",
    "\n",
    "First, need to make sure you have the `text8` file installed, or, if not, download and unzip it to the directory this notebook is in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "if not os.path.isfile('text8'):\n",
    "    !wget -c http://mattmahoney.net/dc/text8.zip\n",
    "    !unzip text8.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collocation detection\n",
    "\n",
    "This is a step you might not see in all word embedding tutorials around. However, if you closely read papers by Mikolov and other \"pioneers\" of word embeddings, you will see that they almost always **make sure to use this preprocessing step**. As homework, try building word embeddings with and without collocations; If the text corpus is big enough (possibly needs to be larger than `text8`), you will be able observe significant performance differences. More obviously, you cannot find an embedding for a collocation (e.g., \"New York\") without feeding the actual collocation (instead of the individual tokens) to the model in the first place.\n",
    "\n",
    "Only if not yet done: open the file, read the tokens, detect all phrases (aka. collocations, idioms), and write the collocations back out (while joining the with an underscore, and joining the remaining tokens with spaces [again]):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw n. tokens = 17005207\n",
      "collocated n. tokens = 15682363\n",
      "\n",
      "anarchism originated as a term of abuse first used against early working_class radicals including the diggers of the english revolution and the sans_culottes of the french_revolution whilst the term is still used in a pejorative way to describe any act that used violent means to destroy the organization of society it has also been taken_up as a positive label by self defined anarchists the word anarchism is derived_from the greek without archons ruler chief king anarchism as a political_philosophy is the belief_that rulers are unnecessary and should_be abolished although there_are differing interpretations of what this means anarchism also refers_to related\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('text8') as f:\n",
    "    tokens = f.read().split()\n",
    "\n",
    "print(\"raw n. tokens =\", len(tokens))\n",
    "\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "\n",
    "# NB: Phrases.__init__ expects sentences\n",
    "collocations = Phraser(Phrases([tokens]))\n",
    "phrases = collocations[tokens]\n",
    "\n",
    "print(\"collocated n. tokens =\", len(phrases))\n",
    "\n",
    "with open('text8_collocations', 'wt') as f:\n",
    "    f.write(\" \".join(phrases))\n",
    "\n",
    "print()\n",
    "HTML(print(\" \".join(phrases[:100])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've done the above step already, you can simply reload the collocation corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "anarchism originated as a term of abuse first used against early working_class radicals including the diggers of the english revolution and the sans_culottes of the french_revolution whilst the term is still used in a pejorative way to describe any act that used violent means to destroy the organization of society it has also been taken_up as a positive label by self defined anarchists the word anarchism is derived_from the greek without archons ruler chief king anarchism as a political_philosophy is the belief_that rulers are unnecessary and should_be abolished although there_are differing interpretations of what this means anarchism also refers_to related"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('text8_collocations') as f:\n",
    "    phrases = f.read().split()\n",
    "    \n",
    "HTML(\" \".join(phrases[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text8_to_sentences(tokens):\n",
    "    \"\"\"The models insist on sentences; Let's build some.\"\"\"\n",
    "    index = 0\n",
    "    inc = 200\n",
    "    \n",
    "    while index + inc < len(tokens):\n",
    "        yield tokens[index:index+inc]\n",
    "        index += inc\n",
    "        \n",
    "    yield tokens[index:]\n",
    "\n",
    "sentences = list(text8_to_sentences(phrases))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "Now that we have generated all collocations for the words, it is a good time to do the actual wembeddings.\n",
    "\n",
    "### [FastText](https://github.com/salestock/fastText.py#api-documentation)\n",
    "\n",
    "Training a FastText model against the text8 text file (around 3 minutes on my MBP, with four corse; Also note that FastText has by a **long** shot the most professional C[++] implementation, so with fewer corse, training times might increase substantially):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20min 24s, sys: 9.93 s, total: 20min 33s\n",
      "Wall time: 3min 14s\n"
     ]
    }
   ],
   "source": [
    "%time ft_sg = fasttext.skipgram('text8_collocations', 'ft-sg') # input/output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size = 111321\n"
     ]
    }
   ],
   "source": [
    "print(\"vocabulary size =\", len(ft_sg.words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "french_revolution 100 [-0.41188904643058777, 0.0858849585056305, -0.3490246534347534, -0.1721481829881668, 0.06440900266170502, 0.23033082485198975, -0.21849319338798523, 0.4249664843082428, 0.5965721607208252, -0.3434455990791321, 0.16860421001911163, 0.7628859877586365, -0.024204956367611885, 0.3768453896045685, -0.28089678287506104, -0.14310553669929504, 0.164326474070549, -0.3946954309940338, 0.29132193326950073, -0.5946333408355713, 0.615812361240387, -0.952389657497406, 0.6845676898956299, 0.9103122353553772, 0.08443176746368408, 0.6040365695953369, -0.6752661466598511, -0.014642216265201569, -0.5868124961853027, -0.2651601731777191, -0.012251163832843304, 0.18524271249771118, -0.17612957954406738, 0.3155304789543152, 0.279428631067276, -0.2875252366065979, -0.22796036303043365, 0.17090444266796112, -0.3238986134529114, -0.4470534026622772, 0.6921630501747131, 0.20638443529605865, -0.2862219214439392, -0.2007114440202713, 0.12906454503536224, -0.42697200179100037, -0.03305406495928764, -0.13852012157440186, 0.4446246325969696, -0.4579632580280304, -0.8165815472602844, -0.31637051701545715, -0.08693895488977432, -0.4701475203037262, -0.18121671676635742, 0.2224673479795456, 0.0844845175743103, 0.42980244755744934, -0.6478444337844849, -0.18849246203899384, 0.6650285720825195, 0.8169909715652466, 0.3090766370296478, 0.2623221278190613, -0.47235479950904846, -1.0029616355895996, 0.620460033416748, -0.26886892318725586, 0.34522661566734314, 0.23450161516666412, 0.22010496258735657, -0.3507613241672516, 0.1547587364912033, 0.5490924715995789, -0.2624497711658478, -0.3678869903087616, -0.23162783682346344, -0.4703572690486908, 0.9471154808998108, -0.31440433859825134, 0.25686419010162354, 0.6966201066970825, -0.2224787473678589, -0.1310393512248993, 0.33563464879989624, 0.36838498711586, 0.6552789807319641, 0.07046899944543839, -0.22332555055618286, 0.047439709305763245, 0.10593672096729279, -0.3595353066921234, -0.061461154371500015, 0.0279481690376997, -0.44921329617500305, 0.23107348382472992, -0.052059900015592575, 0.2946874797344208, 0.37799072265625, -0.011538486927747726]\n"
     ]
    }
   ],
   "source": [
    "vec = ft_sg['french_revolution']\n",
    "print('french_revolution', len(vec), vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrapping the fasttext model with the `gensim` API.\n",
    "\n",
    "Note that `gensim` provides API facilities to [train directly with the FastText binary](http://radimrehurek.com/gensim/models/wrappers/fasttext.html), too. Also, the Python `fasttext` module provides a slightly different (document classification-oriented) API than the `gensim` and `glove_python` (word similarity-oriented) API. As homework, you can figure out how to build the FT model with the `gensim` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "fasttext_model = KeyedVectors.load_word2vec_format('ft-sg.vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [GloVe](https://github.com/maciejkula/glove-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glove import Glove\n",
    "from glove import Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a GloVe model against the text8 corpus (around 2 minutes on my MBP with four cores; note that GloVe has by an equally long shot the probably worst C[++] implementation of the three algorithms):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 20s, sys: 6 s, total: 4min 26s\n",
      "Wall time: 2min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "glove_corpus = Corpus()\n",
    "# NB: Corpus.fit expects sentences\n",
    "glove_corpus.fit(sentences, window=5) # ft & w2v use 5, but GloVe defaults to 10\n",
    "glove_model = Glove(no_components=100) # default is 30, but ft & w2v use 100 dims\n",
    "glove_model.fit(glove_corpus.matrix, no_threads=4) # as many threads as you have cores\n",
    "glove_model.add_dictionary(glove_corpus.dictionary)\n",
    "glove_model.save('glove.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the vocabulary size is (much) larger, because the GloVe API give you no means of filtering infrequent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size = 297728\n"
     ]
    }
   ],
   "source": [
    "print(\"vocabulary size =\", len(glove_corpus.dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "french_revolution: 100 [-0.01457327  0.07042467 -0.00738236  0.01869197 -0.10396932  0.07660629\n",
      " -0.00847388 -0.04022833 -0.08409861 -0.06840466  0.02895287  0.04013232\n",
      "  0.03428275 -0.06931875  0.00244692 -0.09012463  0.07294783 -0.02184141\n",
      " -0.00240382 -0.09255762 -0.03243057  0.12117265 -0.09894675 -0.05349839\n",
      " -0.10930869  0.07230865  0.01685076 -0.0130918   0.01368825  0.08105766\n",
      " -0.01775627  0.08379842  0.09672956  0.04751685  0.11381786  0.08950021\n",
      "  0.08859762  0.0207619   0.10595165  0.11534001  0.08888922  0.06794028\n",
      " -0.04743968  0.0028419  -0.07757577 -0.0749322  -0.11629591 -0.10451072\n",
      " -0.08805415  0.10000175 -0.06882985 -0.00331876  0.03981137  0.01464841\n",
      " -0.04958857 -0.07383062 -0.14829421 -0.06328444 -0.00266095 -0.02554267\n",
      "  0.07958243  0.12405662 -0.02635902 -0.04983661  0.06857486 -0.08566265\n",
      "  0.0715739  -0.01834986 -0.00941419  0.07897407  0.02931605 -0.10223707\n",
      "  0.10103703 -0.06886297  0.03940952 -0.05310901 -0.09632344 -0.04183905\n",
      "  0.08647341  0.03180886  0.11334246 -0.08987108  0.05801108  0.03214467\n",
      " -0.07863435 -0.05061707  0.08406404 -0.04052169 -0.05868995  0.0785046\n",
      " -0.07672644  0.10672427 -0.16514839 -0.09858323 -0.07046706  0.00082469\n",
      "  0.00857652  0.08068983 -0.09423564  0.08063698]\n"
     ]
    }
   ],
   "source": [
    "word_id = glove_corpus.dictionary['french_revolution']\n",
    "vec = glove_model.word_vectors[word_id]\n",
    "print('french_revolution:', len(vec), vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Word2Vec](https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a Word2Vec model against the text8 corpus (around 3 minutes on my MBP, with four cores); Note that skip-grams perform much better than CBOW, but `gensim`'s Word2Vec API defaults to CBOW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 27s, sys: 4.32 s, total: 9min 32s\n",
      "Wall time: 3min 19s\n"
     ]
    }
   ],
   "source": [
    "%time word2vec_model = gensim.models.Word2Vec(list(text8_to_sentences(phrases)), sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=111321, size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "print(word2vec_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, both Word2Vec and FastText are about the same as fast; GloVe, however, is much slower than the other two. This outcome would be very similiary even if you were to use the respective \"raw\" C/C++ implementations of each algorithm's author.\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "Let's do a very unprofessional evaluation: looking at the top 50 words of your corpus. \n",
    "\n",
    "Normally, you would evaluate towards your objective for using the embeddings; E.g., evaluate your classifier (or parser, tagger, ...) you are using with each embedding vector collection we generated above, and possibly also evaluate without using embeddings, and then choose the setup that maximizes your classifier's performance (i.e., your final objective).\n",
    "\n",
    "Another evaluation is to use a long list of similar concept pairs (i.e., including collocations/idioms/phrases). Then you compare that list to random pairings of the concepts and choose the model which maximizes the distance between the similar pairs and the random pairs. Another option (which is used by most word embedding papers) is to compare the correlation is to use the model's predicted similarity (rank) of the pair and compare the average similarity (rank) across models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('french_revolutionary', 0.9696083068847656),\n",
       " ('pre_revolutionary', 0.8272403478622437),\n",
       " ('quiet_revolution', 0.8206069469451904),\n",
       " ('copernican_revolution', 0.8189491629600525),\n",
       " ('glorious_revolution', 0.8126076459884644),\n",
       " ('haitian_revolution', 0.8108875751495361),\n",
       " ('revolutionary_france', 0.800675630569458),\n",
       " ('velvet_revolution', 0.7999899387359619),\n",
       " ('october_revolution', 0.7929908037185669),\n",
       " ('cedar_revolution', 0.7885279655456543),\n",
       " ('cuban_revolution', 0.7873218059539795),\n",
       " ('counter_revolution', 0.7808640003204346),\n",
       " ('violent_revolution', 0.777005672454834),\n",
       " ('mexican_revolution', 0.7757418155670166),\n",
       " ('counterrevolutionary', 0.7704391479492188),\n",
       " ('carnation_revolution', 0.7697211503982544),\n",
       " ('counter_revolutionary', 0.7678598165512085),\n",
       " ('socialist_revolutionary', 0.7639342546463013),\n",
       " ('russian_revolution', 0.7569039463996887),\n",
       " ('revolutionary_war', 0.7538503408432007),\n",
       " ('communist_revolution', 0.7497499585151672),\n",
       " ('bolshevik_revolution', 0.7488869428634644),\n",
       " ('american_revolution', 0.7482515573501587),\n",
       " ('counterrevolutionaries', 0.7477283477783203),\n",
       " ('napoleonic_era', 0.7474905252456665),\n",
       " ('revolution', 0.7448519468307495),\n",
       " ('american_revolutionary', 0.7436498999595642),\n",
       " ('counter_revolutionaries', 0.7391773462295532),\n",
       " ('revolutionary', 0.7355691194534302),\n",
       " ('revolutionibus', 0.7354952096939087),\n",
       " ('french_resistance', 0.7339672446250916),\n",
       " ('spanish_civil', 0.733342170715332),\n",
       " ('matrix_revolutions', 0.7270215749740601),\n",
       " ('permanent_revolution', 0.7255167961120605),\n",
       " ('english_civil', 0.724189043045044),\n",
       " ('revolutions', 0.7218306064605713),\n",
       " ('napoleonic', 0.7210512161254883),\n",
       " ('napoleonic_wars', 0.7163136005401611),\n",
       " ('peasants_revolt', 0.7152740955352783),\n",
       " ('revolutionary_movement', 0.7084944844245911),\n",
       " ('revolutionary_movements', 0.7080354690551758),\n",
       " ('cultural_revolution', 0.7080169916152954),\n",
       " ('charles_v', 0.7058665752410889),\n",
       " ('iranian_revolution', 0.7055966258049011),\n",
       " ('bastille', 0.7039140462875366),\n",
       " ('french_occupation', 0.7037444114685059),\n",
       " ('french_colonial', 0.7030847072601318),\n",
       " ('charles_xii', 0.7001597285270691),\n",
       " ('charles_ix', 0.6989254951477051),\n",
       " ('brumaire', 0.6985522508621216)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_model.most_similar('french_revolution', topn=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('american_revolution', 0.98545719719560509),\n",
       " ('byzantine_empire', 0.98537239752199768),\n",
       " ('immediately_after', 0.98526824795005341),\n",
       " ('julian_calendar', 0.98293441887801969),\n",
       " ('braves', 0.9827548943822858),\n",
       " ('white_sox', 0.98201817386180201),\n",
       " ('crusades', 0.98047823611917062),\n",
       " ('beatles', 0.98038678138099378),\n",
       " ('red_army', 0.97926562174246679),\n",
       " ('fastest', 0.97899027848733544),\n",
       " ('just_before', 0.97854986070970051),\n",
       " ('taliban', 0.97491795114221913),\n",
       " ('browns', 0.97445546919162207),\n",
       " ('royal_navy', 0.97375007741488073),\n",
       " ('holocaust', 0.97346146917545107),\n",
       " ('luftwaffe', 0.97324417882319947),\n",
       " ('khmer_rouge', 0.97291143095959398),\n",
       " ('joins', 0.97289841957820655),\n",
       " ('napoleonic_wars', 0.97282942944594974),\n",
       " ('astros', 0.9726109924660693),\n",
       " ('vikings', 0.97257847329751768),\n",
       " ('us_army', 0.97074014905486095),\n",
       " ('cpr', 0.97036798876359753),\n",
       " ('reformation', 0.96958038092561372),\n",
       " ('ottoman_empire', 0.96940425590643275),\n",
       " ('franks', 0.96936113689026537),\n",
       " ('beach_boys', 0.96933661316916664),\n",
       " ('confederacy', 0.96884317721248681),\n",
       " ('british_empire', 0.96730586885226966),\n",
       " ('hague', 0.96687538429601427),\n",
       " ('new_deal', 0.96646521166357358),\n",
       " ('persian_gulf', 0.96540112843089976),\n",
       " ('british_army', 0.96534207553269369),\n",
       " ('next_year', 0.96530073794147842),\n",
       " ('finishes', 0.9646910783055257),\n",
       " ('most_recent', 0.96467490768229491),\n",
       " ('premiership', 0.96409434040899211),\n",
       " ('cubs', 0.9633005393252968),\n",
       " ('cpc', 0.96310229261078839),\n",
       " ('hijackers', 0.96303119679675475),\n",
       " ('apple_ii', 0.96283651392930636),\n",
       " ('european_parliament', 0.96244857164854902),\n",
       " ('first_round', 0.96228058433941688),\n",
       " ('us_navy', 0.96174052393674703),\n",
       " ('bengals', 0.96159512453130158),\n",
       " ('prohibits', 0.96158149414572192),\n",
       " ('great_depression', 0.96157027862370559),\n",
       " ('korean_war', 0.96156161135546103),\n",
       " ('red_sox', 0.96119039449649435)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_model.most_similar('french_revolution', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('napoleonic', 0.7552270889282227),\n",
       " ('english_civil', 0.7475066184997559),\n",
       " ('american_revolution', 0.746488094329834),\n",
       " ('weimar_republic', 0.7448495030403137),\n",
       " ('glorious_revolution', 0.7405481338500977),\n",
       " ('jacobin', 0.7388259172439575),\n",
       " ('crusading', 0.7386302947998047),\n",
       " ('franco_prussian', 0.7379936575889587),\n",
       " ('napoleonic_wars', 0.7379871010780334),\n",
       " ('inter_war', 0.7285125255584717),\n",
       " ('scottish_independence', 0.7227034568786621),\n",
       " ('french_revolutionary', 0.7222280502319336),\n",
       " ('its_aftermath', 0.7210865020751953),\n",
       " ('emancipation', 0.7207050323486328),\n",
       " ('interwar', 0.7204379439353943),\n",
       " ('pre_revolutionary', 0.7199528813362122),\n",
       " ('jacobins', 0.7196218967437744),\n",
       " ('clausewitz', 0.7180099487304688),\n",
       " ('effectively_ended', 0.7172418832778931),\n",
       " ('paris_commune', 0.7117035388946533),\n",
       " ('brezhnev', 0.704556941986084),\n",
       " ('spanish_civil', 0.7038901448249817),\n",
       " ('nazi_era', 0.7018135786056519),\n",
       " ('were_suppressed', 0.7017765045166016),\n",
       " ('german_empire', 0.7012790441513062),\n",
       " ('storming', 0.7009990811347961),\n",
       " ('austrofascism', 0.6998459696769714),\n",
       " ('revolutions', 0.6989482641220093),\n",
       " ('bastille', 0.6982326507568359),\n",
       " ('third_reich', 0.6978324055671692),\n",
       " ('wannsee_conference', 0.6976219415664673),\n",
       " ('hussite', 0.6968417167663574),\n",
       " ('absolutism', 0.6961326599121094),\n",
       " ('russian_civil', 0.6940321922302246),\n",
       " ('triumvirate', 0.6937726736068726),\n",
       " ('communist_regime', 0.6931082010269165),\n",
       " ('protestant_reformation', 0.6926648616790771),\n",
       " ('republicanism', 0.6924551129341125),\n",
       " ('national_socialist', 0.6923459768295288),\n",
       " ('revolutionary_france', 0.6917819976806641),\n",
       " ('mexican_revolution', 0.6911493539810181),\n",
       " ('russian_revolution', 0.6894921064376831),\n",
       " ('fascists', 0.6885594129562378),\n",
       " ('eighteenth_centuries', 0.6883768439292908),\n",
       " ('stalinism', 0.6880015134811401),\n",
       " ('iconoclastic', 0.687754213809967),\n",
       " ('jacobitism', 0.6874088048934937),\n",
       " ('bolshevik', 0.6874052286148071),\n",
       " ('indian_independence', 0.6864299774169922),\n",
       " ('constitutionalism', 0.6860508918762207)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.most_similar('french_revolution', topn=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "FastText is certainly more character-content oriented due to its reliance on character n-grams, and both it and Word2Vec have the advantage that they are (much - particularly notable on on very large corpora) faster than GloVe. Also note that GloVe's similarty scores decay much slower. But at the end of the day, the right choice is more a question of personal taste than anything else. One noteworthy advantage for `gensim`'s Word2Vec implementation is that the model can be updated with new documents at a later data (\"online training\"). Yours Truly prefers FastText, due to the above reasons and because the character n-gram embeddings provide a good backup strategy for unseen words, but the best rule as always is: Test all approaches against your objective!\n",
    "\n",
    "## Post scriptum\n",
    "\n",
    "Yes, with the `gensim` embedding model API, you can do *that*, too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.6721546649932861),\n",
       " ('crown_prince', 0.6700811386108398),\n",
       " ('empress', 0.6549503803253174),\n",
       " ('wife', 0.654847264289856),\n",
       " ('matilda', 0.6330344080924988),\n",
       " ('throne', 0.6304331421852112),\n",
       " ('jadwiga', 0.6300833225250244),\n",
       " ('emperor', 0.622090220451355),\n",
       " ('anjou', 0.6076939105987549),\n",
       " ('queen_consort', 0.6069934368133545)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hurray!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
